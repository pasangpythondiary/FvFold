{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pasang/anaconda3/envs/antibody/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Replace this file with your own (multi-)FASTA\n",
    "# Headers are expected to start with \">\";\n",
    "\n",
    "# whether to retrieve embeddings for each residue in a protein \n",
    "# --> Lx1024 matrix per protein with L being the protein's length\n",
    "# as a rule of thumb: 1k proteins require around 1GB RAM/disk\n",
    "per_residue = True \n",
    "per_residue_path = \"./protT5/output/per_residue_embeddings.h5\" # where to store the embeddings\n",
    "\n",
    "# whether to retrieve per-protein embeddings \n",
    "# --> only one 1024-d vector per protein, irrespective of its length\n",
    "per_protein = False\n",
    "per_protein_path = \"./protT5/output/per_protein_embeddings.h5\" # where to store the embeddings\n",
    "\n",
    "# whether to retrieve secondary structure predictions\n",
    "# This can be replaced by your method after being trained on ProtT5 embeddings\n",
    "sec_struct = False\n",
    "sec_struct_path = \"./protT5/output/ss3_preds.fasta\" # file for storing predictions\n",
    "\n",
    "# make sure that either per-residue or per-protein embeddings are stored\n",
    "assert per_protein is True or per_residue is True or sec_struct is True, print(\n",
    "    \"Minimally, you need to active per_residue, per_protein or sec_struct. (or any combination)\")\n",
    "\n",
    "#@title Import dependencies and check whether GPU is available. { display-mode: \"form\" }\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "import torch\n",
    "import h5py\n",
    "import time\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# print(\"Using {}\".format(device))\n",
    "\n",
    "#@title Network architecture for secondary structure prediction. { display-mode: \"form\" }\n",
    "# Convolutional neural network (two convolutional layers) to predict secondary structure\n",
    "class ConvNet( torch.nn.Module ):\n",
    "    def __init__( self ):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # This is only called \"elmo_feature_extractor\" for historic reason\n",
    "        # CNN weights are trained on ProtT5 embeddings\n",
    "        self.elmo_feature_extractor = torch.nn.Sequential(\n",
    "                        torch.nn.Conv2d( 1024, 32, kernel_size=(7,1), padding=(3,0) ), # 7x32\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout( 0.25 ),\n",
    "                        )\n",
    "        n_final_in = 32\n",
    "        self.dssp3_classifier = torch.nn.Sequential(\n",
    "                        torch.nn.Conv2d( n_final_in, 3, kernel_size=(7,1), padding=(3,0)) # 7\n",
    "                        )\n",
    "        \n",
    "        self.dssp8_classifier = torch.nn.Sequential(\n",
    "                        torch.nn.Conv2d( n_final_in, 8, kernel_size=(7,1), padding=(3,0))\n",
    "                        )\n",
    "        self.diso_classifier = torch.nn.Sequential(\n",
    "                        torch.nn.Conv2d( n_final_in, 2, kernel_size=(7,1), padding=(3,0))\n",
    "                        )\n",
    "        \n",
    "\n",
    "    def forward( self, x):\n",
    "        # IN: X = (B x L x F); OUT: (B x F x L, 1)\n",
    "        x = x.permute(0,2,1).unsqueeze(dim=-1) \n",
    "        x         = self.elmo_feature_extractor(x) # OUT: (B x 32 x L x 1)\n",
    "        d3_Yhat   = self.dssp3_classifier( x ).squeeze(dim=-1).permute(0,2,1) # OUT: (B x L x 3)\n",
    "        d8_Yhat   = self.dssp8_classifier( x ).squeeze(dim=-1).permute(0,2,1) # OUT: (B x L x 8)\n",
    "        diso_Yhat = self.diso_classifier(  x ).squeeze(dim=-1).permute(0,2,1) # OUT: (B x L x 2)\n",
    "        return d3_Yhat, d8_Yhat, diso_Yhat\n",
    "    \n",
    "\n",
    "\n",
    "#@title Load encoder-part of ProtT5 in half-precision. { display-mode: \"form\" }\n",
    "# Load ProtT5 in half-precision (more specifically: the encoder-part of ProtT5-XL-U50) \n",
    "def get_T5_model():\n",
    "    model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\")\n",
    "    model = model.to(device) # move model to GPU\n",
    "    model = model.eval() # set model to evaluation model\n",
    "    tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_half_uniref50-enc', do_lower_case=False)\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "#@title Read in file in fasta format. { display-mode: \"form\" }\n",
    "def read_fasta( fasta_path, split_char=\"!\", id_field=0):\n",
    "    '''\n",
    "        Reads in fasta file containing multiple sequences.\n",
    "        Split_char and id_field allow to control identifier extraction from header.\n",
    "        E.g.: set split_char=\"|\" and id_field=1 for SwissProt/UniProt Headers.\n",
    "        Returns dictionary holding multiple sequences or only single \n",
    "        sequence, depending on input file.\n",
    "    '''\n",
    "    \n",
    "    seqs = dict()\n",
    "    with open( fasta_path, 'r' ) as fasta_f:\n",
    "        for line in fasta_f:\n",
    "            # get uniprot ID from header and create new entry\n",
    "            if line.startswith('>'):\n",
    "                uniprot_id = line.replace('>', '').strip().split(split_char)[id_field]\n",
    "                # replace tokens that are mis-interpreted when loading h5\n",
    "                uniprot_id = uniprot_id.replace(\"/\",\"_\").replace(\".\",\"_\")\n",
    "                seqs[ uniprot_id ] = ''\n",
    "            else:\n",
    "                # repl. all whie-space chars and join seqs spanning multiple lines, drop gaps and cast to upper-case\n",
    "                seq= ''.join( line.split() ).upper().replace(\"-\",\"\")\n",
    "                # repl. all non-standard AAs and map them to unknown/X\n",
    "                seq = seq.replace('U','X').replace('Z','X').replace('O','X')\n",
    "                seqs[ uniprot_id ] += seq \n",
    "    example_id=next(iter(seqs))\n",
    "    # print(\"Read {} sequences.\".format(len(seqs)))\n",
    "    # print(\"Example:\\n{}\\n{}\".format(example_id,seqs[example_id]))\n",
    "\n",
    "    return seqs\n",
    "\n",
    "\n",
    "#@title Generate embeddings. { display-mode: \"form\" }\n",
    "# Generate embeddings via batch-processing\n",
    "# per_residue indicates that embeddings for each residue in a protein should be returned.\n",
    "# per_protein indicates that embeddings for a whole protein should be returned (average-pooling)\n",
    "# max_residues gives the upper limit of residues within one batch\n",
    "# max_seq_len gives the upper sequences length for applying batch-processing\n",
    "# max_batch gives the upper number of sequences per batch\n",
    "def get_embeddings( model, tokenizer, seqs, per_residue, per_protein, sec_struct, \n",
    "                   max_residues=4000, max_seq_len=1000, max_batch=100 ):\n",
    "\n",
    "    if sec_struct:\n",
    "      sec_struct_model = load_sec_struct_model()\n",
    "\n",
    "    results = {\"residue_embs\" : dict(), \n",
    "               \"protein_embs\" : dict(),\n",
    "               \"sec_structs\" : dict() \n",
    "               }\n",
    "\n",
    "    # sort sequences according to length (reduces unnecessary padding --> speeds up embedding)\n",
    "    seq_dict   = sorted( seqs.items(), key=lambda kv: len( seqs[kv[0]] ), reverse=True )\n",
    "    start = time.time()\n",
    "    batch = list()\n",
    "    for seq_idx, (pdb_id, seq) in enumerate(seq_dict,1):\n",
    "        seq = seq\n",
    "        seq_len = len(seq)\n",
    "        seq = ' '.join(list(seq))\n",
    "        batch.append((pdb_id,seq,seq_len))\n",
    "\n",
    "        # count residues in current batch and add the last sequence length to\n",
    "        # avoid that batches with (n_res_batch > max_residues) get processed \n",
    "        n_res_batch = sum([ s_len for  _, _, s_len in batch ]) + seq_len \n",
    "        if len(batch) >= max_batch or n_res_batch>=max_residues or seq_idx==len(seq_dict) or seq_len>max_seq_len:\n",
    "            pdb_ids, seqs, seq_lens = zip(*batch)\n",
    "            batch = list()\n",
    "\n",
    "            # add_special_tokens adds extra token at the end of each sequence\n",
    "            token_encoding = tokenizer.batch_encode_plus(seqs, add_special_tokens=True, padding=\"longest\")\n",
    "            input_ids      = torch.tensor(token_encoding['input_ids']).to(device)\n",
    "            attention_mask = torch.tensor(token_encoding['attention_mask']).to(device)\n",
    "            \n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    # returns: ( batch-size x max_seq_len_in_minibatch x embedding_dim )\n",
    "                    embedding_repr = model(input_ids, attention_mask=attention_mask)\n",
    "            except RuntimeError:\n",
    "                print(\"RuntimeError during embedding for {} (L={})\".format(pdb_id, seq_len))\n",
    "                continue\n",
    "\n",
    "            if sec_struct: # in case you want to predict secondary structure from embeddings\n",
    "              d3_Yhat, d8_Yhat, diso_Yhat = sec_struct_model(embedding_repr.last_hidden_state)\n",
    "\n",
    "\n",
    "            for batch_idx, identifier in enumerate(pdb_ids): # for each protein in the current mini-batch\n",
    "                s_len = seq_lens[batch_idx]\n",
    "                # slice off padding --> batch-size x seq_len x embedding_dim  \n",
    "                emb = embedding_repr.last_hidden_state[batch_idx,:s_len]\n",
    "                if sec_struct: # get classification results\n",
    "                    results[\"sec_structs\"][identifier] = torch.max( d3_Yhat[batch_idx,:s_len], dim=1 )[1].detach().cpu().numpy().squeeze()\n",
    "                if per_residue: # store per-residue embeddings (Lx1024)\n",
    "                    results[\"residue_embs\"][ identifier ] = emb.detach().cpu().numpy().squeeze()\n",
    "                if per_protein: # apply average-pooling to derive per-protein embeddings (1024-d)\n",
    "                    protein_emb = emb.mean(dim=0)\n",
    "                    results[\"protein_embs\"][identifier] = protein_emb.detach().cpu().numpy().squeeze()\n",
    "\n",
    "\n",
    "    passed_time=time.time()-start\n",
    "    avg_time = passed_time/len(results[\"residue_embs\"]) if per_residue else passed_time/len(results[\"protein_embs\"])\n",
    "    # print('\\n############# EMBEDDING STATS #############')\n",
    "    # print('Total number of per-residue embeddings: {}'.format(len(results[\"residue_embs\"])))\n",
    "    # print('Total number of per-protein embeddings: {}'.format(len(results[\"protein_embs\"])))\n",
    "    # print(\"Time for generating embeddings: {:.1f}[m] ({:.3f}[s/protein])\".format(\n",
    "    #     passed_time/60, avg_time ))\n",
    "    # print('\\n############# END #############')\n",
    "    return results\n",
    "\n",
    "#@title Write embeddings to disk. { display-mode: \"form\" }\n",
    "def save_embeddings(emb_dict,out_path):\n",
    "    with h5py.File(str(out_path), \"w\") as hf:\n",
    "        for sequence_id, embedding in emb_dict.items():\n",
    "            # noinspection PyUnboundLocalVariable\n",
    "            hf.create_dataset(sequence_id, data=embedding)\n",
    "    return None\n",
    "\n",
    "#@title Write predictions to disk. { display-mode: \"form\" }\n",
    "def write_prediction_fasta(predictions, out_path):\n",
    "  class_mapping = {0:\"H\",1:\"E\",2:\"L\"} \n",
    "  with open(out_path, 'w+') as out_f:\n",
    "      out_f.write( '\\n'.join( \n",
    "          [ \">{}\\n{}\".format( \n",
    "              seq_id, ''.join( [class_mapping[j] for j in yhat] )) \n",
    "          for seq_id, yhat in predictions.items()\n",
    "          ] \n",
    "            ) )\n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seq_path = \"/home/pasang/all_experiment/AB_Fold/data/sample_files/4h0h.fasta\"\n",
    "import torch\n",
    "import numpy as np\n",
    "# Load the encoder part of ProtT5-XL-U50 in half-precision (recommended)\n",
    "model, tokenizer = get_T5_model()\n",
    "\n",
    "# Load example fasta.\n",
    "seqs = read_fasta( seq_path )\n",
    "\n",
    "# Compute embeddings and/or secondary structure predictions\n",
    "results = get_embeddings( model, tokenizer, seqs,\n",
    "                        per_residue, per_protein, sec_struct)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([':H', ':L'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"residue_embs\"].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 1024)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"residue_embs\"][\":H\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 1024)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"residue_embs\"][\":L\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([118, 1024])\n",
      "[tensor([[-0.2224, -0.1996, -0.0176,  ...,  0.1179, -0.1415,  0.0386],\n",
      "        [ 0.2032,  0.2652, -0.4877,  ...,  0.3343,  0.1450, -0.1008],\n",
      "        [ 0.1834,  0.0114,  0.2356,  ...,  0.3739,  0.3714, -0.1349],\n",
      "        ...,\n",
      "        [ 0.0979,  0.1837,  0.2137,  ...,  0.0487,  0.3230,  0.0484],\n",
      "        [ 0.0558,  0.0703, -0.1255,  ..., -0.0917,  0.0780, -0.2170],\n",
      "        [ 0.0998,  0.0220,  0.2996,  ..., -0.0349,  0.0428, -0.0970]])]\n",
      "torch.Size([112, 1024])\n",
      "[tensor([[-0.2224, -0.1996, -0.0176,  ...,  0.1179, -0.1415,  0.0386],\n",
      "        [ 0.2032,  0.2652, -0.4877,  ...,  0.3343,  0.1450, -0.1008],\n",
      "        [ 0.1834,  0.0114,  0.2356,  ...,  0.3739,  0.3714, -0.1349],\n",
      "        ...,\n",
      "        [ 0.0979,  0.1837,  0.2137,  ...,  0.0487,  0.3230,  0.0484],\n",
      "        [ 0.0558,  0.0703, -0.1255,  ..., -0.0917,  0.0780, -0.2170],\n",
      "        [ 0.0998,  0.0220,  0.2996,  ..., -0.0349,  0.0428, -0.0970]]), tensor([[-0.1311, -0.1917, -0.0988,  ...,  0.1328, -0.0190,  0.0093],\n",
      "        [-0.0766,  0.1384, -0.5984,  ...,  0.2867,  0.0528, -0.1346],\n",
      "        [ 0.0792,  0.1773, -0.0888,  ..., -0.0687,  0.2253, -0.1809],\n",
      "        ...,\n",
      "        [-0.0191,  0.0970,  0.0940,  ...,  0.0810,  0.1368,  0.1976],\n",
      "        [ 0.1473, -0.0886, -0.0916,  ..., -0.2095,  0.1773, -0.0674],\n",
      "        [ 0.0045, -0.0842,  0.2929,  ..., -0.0413,  0.0851, -0.2215]])]\n"
     ]
    }
   ],
   "source": [
    "#concatenating heavy and light sequence\n",
    "# initialize an empty list to store tensors\n",
    "tensor_list = []\n",
    "\n",
    "# iterate over all values in the dictionary\n",
    "for value in results[\"residue_embs\"].values():\n",
    "    # check if the value is a NumPy array\n",
    "    if isinstance(value, np.ndarray):\n",
    "        # convert the array to a PyTorch tensor\n",
    "        tensor = torch.from_numpy(value)\n",
    "    elif isinstance(value, torch.Tensor):\n",
    "        tensor = value\n",
    "    else:\n",
    "        # skip non-tensor values\n",
    "        continue\n",
    "    # add the tensor to the list\n",
    "    print(tensor.shape)\n",
    "    tensor_list.append(tensor)\n",
    "    print(tensor_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([230, 1024])\n"
     ]
    }
   ],
   "source": [
    "# concatenate tensors along 0th dimension if they have the same shape\n",
    "if len(tensor_list) > 1:\n",
    "    concatenated_tensor = torch.cat(tensor_list, dim=0)\n",
    "else:\n",
    "    concatenated_tensor = tensor_list[0]\n",
    "print(concatenated_tensor.shape)\n",
    "\n",
    "\n",
    "# print(new_embedding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024, 230])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_embedding = concatenated_tensor\n",
    "\n",
    "# print(new_embedding.shape)\n",
    "#transpose shape from sequence legth to 128 to 128, sequence length\n",
    "new_embedding=new_embedding.transpose(1,0)\n",
    "# print(new_embedding.shape)\n",
    "#adding extra dimention eg 1,123,sequence length\n",
    "new_embedding=torch.unsqueeze(new_embedding, 0)\n",
    "print(new_embedding.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "antibody",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4aa1b9ed64ceffde4e9ec8fae6a09901f619502af945619ec22cc09864d41a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
